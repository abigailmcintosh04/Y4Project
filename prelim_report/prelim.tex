% !TeX program = latexmk
% !TeX outputDirectory = build
\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[a4paper, margin=2cm]{geometry}
\usepackage{hyperref}

\begin{document}

\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        \Huge
        \textbf{Exploring Heavy Quark Fragmentation with Machine Learning at ATLAS}
        
        \vspace{0.5cm}
        \LARGE
        Preliminary Report
            
        \vspace{1.5cm}
        \textbf{Abigail McIntosh}
        
        \vfill
        \vspace{0.8cm}
            
            
        \Large
        School of Physics and Astronomy\\
        University of Birmingham\\
        December 2025\\
    \end{center}
\end{titlepage}

\pagenumbering{roman}
\tableofcontents

\pagebreak
\pagenumbering{arabic}


\section{Introduction}

\subsection{Perturbative and Non-Perturbative QCD}
Quantum Chromodynamics (QCD) is the quantum theory that describes the strong interaction between quarks, that is mediated by gluons. A key difference between QCD and Quantum Electrodynamics (QED) is that QCD is non-Abelian gauge theory, which leads to gluons carrying the colour charge. This also means that gluons are self-coupling. This self-coupling leads to the two ranges of QCD: asymptotic freedom and confinement. Under asymptotic freedom at high energies, the strong coupling constant $\alpha_s \ll 1$, meaning perturbative calculations (pQCD) can be used. Under confinement at low energies, $\alpha_s \sim 1$, meaning a non-perturbative approach is necessary. 

For pp collisions at the LHC, the hard scattering process occurs at high energies, meaning pQCD can be used to describe it. However, the fragmentation occurs at low energies, meaning pQCD cannot be used to describe it, and are instead described by phenomenological models. The two approaches required to describe the collisions are connected by the factorisation theorem, which states that the cross section can be split into three parts: the parton distribution functions (PDFs), the hard scatter, and the fragmentation functions.

\subsection{Fragmentation and Universality}
Fragmentation is the non-perturbative process by which coloured partons, i.e. quarks and gluons, are confined into colourless hadrons. The fragmentation function $D^h_i(x, \mu^2) (i=q,\bar{q},g)$ describes the probability density that a certain outgoing parton $i$ produces a hadron $h$, where $x$ is the fraction of the parton's momentum transferred to the hadron and $\mu$ is the factorisation scale \cite{pdg2018}.

Historically, it has been assumed fragmentation functions are universal, meaning they are independent of the hard scattering process. This means fragmentation functions should be the same for pp collisions as for e$^+$e$^-$ collisions. However, recent measurements of charm quark hadronisation in the ALICE collaboration found a larger fraction hadronising into baryons in pp collisions compared to e$^+$e$^-$ collisions \cite{alice2023charm}, suggesting fragmentation may not be universal and instead dependent on the environment.


\section{Event Generation}
To train the machine learning model, Monte Carlo (MC) simulated events are used. The events are generated using PYTHIA 8 \cite{pythia8}, generating pp collisions at $\sqrt{s} = 13$ TeV. To ensure only charm events are generated, the enabled hard QCD processes are qq $\rightarrow$ c\={c} and gg $\rightarrow$ c\={c}. A minimum transverse momentum of 20 GeV is set for the hard scatter to ensure the events are jet-like in nature. Initial and final state radiation and hadronisation are enabled, while multiple parton interactions are disabled. 

For each final state particle in a PYTHIA event, a FastJet \cite{fastjet} PseudoJet object is created. The pseudojets are then clustered using the anti-$k_t$ algorithm, with a radius parameter of R = 0.4, to form jets.The jets are then matched to the charm quarks via a $\Delta R$ matching, where $\Delta R = \sqrt{(\Delta \eta)^2 + (\Delta \phi)^2}$, with a maximum $\Delta R$ of 0.4. 

\subsection{Lund String Model}
PYTHIA uses the Lund string model to simulate hadronisation. In this model, when a quark-antiquark pair is separated, the gluon field lines collapse into a flux tube, or string. The potential energy stored in the string increases linearly with the separation distance, $V(r) = \kappa r$, where $\kappa$ is the string tension, approximately 1 GeV/fm. When it becomes energetically favourable, the string will break, creating a new quark-antiquark pair. The probability of creating a pair of mass $\mu$ with transverse momentum $p_{\perp}$ is given by:

\begin{equation}
    P(m) \propto \exp\left(-\frac{\pi (\mu^2 + p_{\perp}^2)}{\kappa}\right),
\end{equation}

meaning the production of heavier quarks (charm and bottom) is suppressed \cite{lundmodel}. Therefore, the production of $\Lambda_c$ baryons (quark content udc) is suppressed compared to D mesons (containing one charm quark and another light quark). The mass of a ud-\={u}\={d} diquark is much larger than a u\={u} or d\={d} pair, with the suppression of diquark production to quark production in PYTHIA defined as 0.081 \cite{pythia8}, where universality is assumed.

\section{Machine Learning}
To explore the fragmentation of charm quarks, a machine learning model will be developed to classify jets based on the charmed hadron(s) they contain, i.e. D mesons or $\Lambda_c$ baryons. The current approach of reconstruction requires identifying all the decay products of the charmed hadron, leading to low reconstruction efficiency. To solve this, a machine learning model will be used to classify jets based on their overall properties, increasing efficiency. This model will be trained with the Monte Carlo simulated events described in Section 2.

\subsection{Input Features}
As the D mesons and $\Lambda_c$ baryons have different lifetimes, masses, and decay properties, the jets containing them are expected to have slightly different properties. Distinguishing variables can be generated from the energy-momentum four vectors of the jet constituents. It is necessary to limit the distinguishing variables to ones that could be calculated from the data available from the ATLAS detector so that when the machine learning algorithm is applied onto real data, the distinguishing variables can still be calculated.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        Hadron & Quark Content & Mass (MeV) & Lifetime (fs) \\
        \hline \\
        $D^0$ & $c\bar{u}$ & $1864.84 \pm 0.05$ & $410.3 \pm 1.0$ \\
        $D^+$ & $c\bar{d}$ & $1869.5 \pm 0.4$ & $1033 \pm 5$ \\
        $D_s^+$ & $c\bar{s}$ & $1969.0 \pm 1.4$ & $501.2 \pm 2.2$ \\
        $\Lambda_c^+$ & $udc$ & $2286.46 \pm 0.14$ & $202.6 \pm 1.0$ \\
        \hline
    \end{tabular}
    \caption{Properties of charmed hadrons being used.}
    \label{tab:charm_props}
\end{table}

Two main distinguishing variables that have been identified so far are $L_{xy}$, which is the transverse decay length of the charmed hadron, and $d_0$, which is the transverse impact parameter of the charmed hadron. They are defined as follows:
\begin{equation}
    L_{xy} = \sqrt{(x_{SV}-x_{PV})^2 + (y_{SV}-y_{PV})^2},
\end{equation}
where $(x_{SV}$ and $y_{SV})$ are the x and y coordinates of the secondary vertex (SV) of the charmed hadron decay, and $(x_{PV}$ and $y_{PV})$ are the x and y coordinates of the primary vertex (PV) of the initial hard scattering;
\begin{equation}
    d_0 = \frac{1}{p_T} (x_{PV} p_y - y_{PV} p_x),
\end{equation}
where $p_T$ is the transverse momentum of the charmed hadron, $p_x$ and $p_y$ are the x and y components of the momentum of the charmed hadron, and $(x_{PV}, y_{PV})$ are as defined above.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{images/vertices.png}
    \caption{Diagram showing a typical decay of a charmed hadron at ATLAS, showing the primary and secondary vertices, as well as $L_{xy}$ and $d_0$ \cite{atlas2021triggers}.}
    \label{fig:vertices}
\end{figure}

As can be seen in \ref{fig:vertices}, $L_{xy}$ and $d_0$ are directly related to the displacement of the charmed hadron from the PV. For $L_{xy}$, as this is the transverse distance between the PV and SV, this is directly related to the hadron's lifetime. For $d_0$, as this is the distance of closest approach of the track to the PV, tracks from longer lived hadtons will on average have a larger $d_0$.

As can be seen in Table \ref{tab:charm_props}, the lifetimes of the $D_s^+$ and the $D_0$ mesons are similar, within 100fs of each other. This means that purely relying on lifetime-related variables such as $L_{xy}$ and $d_0$ may not be sufficient to distinguish between jets containing those mesons. As a result, distinguishing variables related to the mass will also be investigated.

Mass-based variables require a more nuanced approach. The current approach for calculating lifetime-related summary variables is to take averages across all jet constituents, not just those from the charmed hadron, as despite having the truth information to know which constituents come from the charmed hadron in the event generation, this information will not be available when using real data. The differing values of the lifetime-related variables will affect the averages across the whole jet, meaning this approach is valid. However, for mass-based variables, as the hadron mass is only a small fraction of the total jet mass, the effect on the average could be too small to detect. Hence, an alternative approach was taken, where tracks were filtered based on their $d_0$. Summary variables were calculated for tracks with a $d_0$ above a specific threshold, as those tracks are more likely to have originated from the charmed hadron.


\section{Future Plans}

\subsection{Detector Simulation and Realism}
To further improve the realism of the event generator, a detector will be simulated, possibly using DELPHES. This will allow detector effects, such as efficiency, resolution (via a Gaussian smear) and rejection of high pseudorapidity events, to be included in the simulation. This will improve the realism of the event generation, leading to more accurate training of the machine learning model.

\bibliographystyle{plain}
\bibliography{references}

\end{document}